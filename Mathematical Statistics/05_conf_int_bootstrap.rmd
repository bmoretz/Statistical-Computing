---
title: ''
mainfont: Arial
fontsize: 12pt
documentclass: report
header-includes:
- \PassOptionsToPackage{table}{xcolor}
- \usepackage{caption}
- \usepackage{amssymb}
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{wrapfig}
- \usepackage{float}
- \usepackage{colortbl}
- \usepackage{pdflscape}
- \usepackage{tabu}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage[normalem]{ulem}
- \usepackage{makecell}
- \usepackage[table]{xcolor}
- \usepackage{fancyhdr}
- \usepackage{boldline}
- \usepackage{tipa}
   \definecolor{headergrey}{HTML}{545454}
   \definecolor{msdblue}{HTML}{1C93D1}
   \pagestyle{fancy}
   \setlength\headheight{30pt}
   \rhead{\color{headergrey}\today}
   \fancyhead[L]{\color{headergrey}Moretz, Brandon}
   \fancyhead[C]{\Large\bfseries\color{headergrey}Confidence Intervals - The Bootstrap}
   \rfoot{\color{headergrey}\thepage}
   \lfoot{\color{headergrey}Chapter 5}
   \fancyfoot[C]{\rmfamily\color{headergrey}Mathematical Statistics}
geometry: left = 1cm, right = 1cm, top = 2cm, bottom = 3cm
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    fig_caption: yes
    latex_engine: xelatex
editor_options: 
  chunk_output_type: console
---


```{r knitr_setup, include = FALSE}
knitr::opts_chunk$set(
   echo = T, 
   eval = TRUE, 
   dev = 'png', 
   fig.width = 9, 
   fig.height = 3.5)

options(knitr.table.format = "latex")
```

```{r report_setup, message = FALSE, warning = FALSE, include = FALSE}

library(data.table, quietly = TRUE, warn.conflicts = FALSE)

assignInNamespace("cedta.pkgEvalsUserCode", c(data.table:::cedta.pkgEvalsUserCode, "rtvs"), "data.table")

library(ggplot2, quietly = TRUE, warn.conflicts = FALSE)
library(ggrepel, quietly = TRUE, warn.conflicts = FALSE)
library(ggthemes, quietly = TRUE, warn.conflicts = FALSE)
library(knitr, quietly = TRUE, warn.conflicts = FALSE)
library(kableExtra, quietly = TRUE, warn.conflicts = FALSE)
library(Rblpapi, quietly = TRUE, warn.conflicts = FALSE)
library(scales, quietly = TRUE, warn.conflicts = FALSE)
library(pander, quietly = TRUE, warn.conflicts = FALSE)
library(dplyr, quietly = TRUE, warn.conflicts = FALSE)
library(formattable, quietly = TRUE, warn.conflicts = FALSE)
library(grid, quietly = TRUE, warn.conflicts = FALSE)
library(gridExtra, quietly = TRUE, warn.conflicts = FALSE)
library(png, quietly = TRUE, warn.conflicts = FALSE)
library(extrafont, quietly = TRUE, warn.conflicts = FALSE)
library(tinytex, quietly = TRUE, warn.conflicts = FALSE)
library(stringr, quietly = TRUE, warn.conflicts = FALSE)
library(lubridate, quietly = TRUE, warn.conflicts = FALSE)
library(reshape2, quietly = TRUE, warn.conflicts = FALSE)
library(ggrepel, quietly = TRUE, warn.conflicts = FALSE)
library(gtools, quietly = TRUE, warn.conflicts = FALSE)
library(here, quietly = T, warn.conflicts = F)
library(boot, quietly = T, warn.conflicts = F)
library(ggExtra, quietly = T, warn.conflicts = F)

options(tinytex.verbose = TRUE)
suppressMessages(library("tidyverse"))

pretty_kable <- function(data, title, dig = 2) {
  kable(data, caption = title, digits = dig) %>%
    kable_styling(bootstrap_options = c("striped", "hover")) %>%
      kableExtra::kable_styling(latex_options = "hold_position")
}

theme_set(theme_light())

# Theme Overrides
theme_update(axis.text.x = element_text(size = 10),
             axis.text.y = element_text(size = 10),
             plot.title = element_text(hjust = 0.5, size = 16, face = "bold", color = "darkgreen"),
             axis.title = element_text(face = "bold", size = 12, colour = "steelblue4"),
             plot.subtitle = element_text(face = "bold", size = 8, colour = "darkred"),
             legend.title = element_text(size = 12, color = "darkred", face = "bold"),
             legend.position = "right", legend.title.align=0.5,
             panel.border = element_rect(linetype = "solid", 
                                         colour = "lightgray"), 
             plot.margin = unit(c( 0.1, 0.1, 0.1, 0.1), "inches"))

data.dir <- paste0(here::here(), "/datasets/")
```

```{r pander_setup, include = FALSE}

knitr::opts_chunk$set(comment = NA)

panderOptions('table.alignment.default', function(df)
    ifelse(sapply(df, is.numeric), 'right', 'left'))
panderOptions('table.split.table', Inf)
panderOptions('big.mark', ",")
panderOptions('keep.trailing.zeros', TRUE)

```

#### 5.1

Consider the samples 1-6. Use a six-sided die to obtain three different bootstrap samples and their corresponding means.

```{r,echo=T}
pop <- seq(from = 1, to = 6, by = 1)

n <- 6

s1 <- mean( sample(pop, n, replace = T) )
s2 <- mean( sample(pop, n, replace = T) )
s3 <- mean( sample(pop, n, replace = T) )

```

$\bar{x}^*_1 = `r s1`$, $\bar{x}^*_2 = `r s2`$, $\bar{x}^*_3 = `r s3`$

#### 5.2

Consider the samples 1, 3, 4, and 6 from some distribution.

```{r, echo = T}

pop <- c(1, 3, 4, 6)

samples <- permutations(n = 4, r = 4, pop, repeats.allowed = T)

```

a.) For one random bootstrap sample, find the probability that the mean is one.

```{r, echo = T}

means <- apply(samples, 1, mean)

p <- mean( means == 1 )
```

Probability: __`r round(p, 4) * 100`%__

b.) For one random bootstrap sample, find the probability that the maximum is 6.

```{r, echo = T}
maxes <- apply(samples, 1, max)

p <- mean( maxes == 6 )
```

Probability: __`r round(p, 4) * 100`%__

c.) For one random bootstrap sample, find the probability that exactly two elements in the sample are less than 2.

```{r, echo = T}

lt2 <- apply(t(apply(samples, 1, function(x) { x < 2})), 1, sum)

p <- mean( lt2 == 2 )
```

Probability: __`r round(p, 4) *100`%__

### 5.3

Consider the sample 1-3.

a.) List all the (ordered) bootstrap samples from this sample. How many are there?

```{r, echo = T}
samples <- permutations(n = 3, r = 3, 1:3, repeats.allowed = T)

n <- nrow(samples)
```

Samples: = $3^3$ = __`r n`__

b.) How many unordered bootstrap samples are there? For example, {1, 2, 2} and {2, 1, 2} are considered to be the same.

```{r}
samples <- combinations(n = 3, r = 3, 1:3, repeats.allowed = T)

n <- nrow(samples)

assertthat::are_equal(n, choose(3 + 3 - 1, 3))
```

Samples: = $5 \choose 3$ = __`r n`__

c.) How many ordered bootstrap samples have one occurrence of 1 and two occurences of 3?

```{r}
samples <- permutations(n = 3, r = 3, 1:3, repeats.allowed = T)

n.ones <- apply(t(apply(samples, 1, FUN = function(x) { x == 1 })), 1, function(x) sum(x) )
n.threes <- apply(t(apply(samples, 1, FUN = function(x) { x == 3 })), 1, function(x) sum(x) )

sum((n.ones == 1 & n.threes == 2) == T)
```

Is this the same number of bootstrap samples that have each of 1, 2 and 3 occuring exactly once?

```{r}

n.ones <- apply(t(apply(samples, 1, FUN = function(x) { x == 1 })), 1, function(x) sum(x) )
n.twos <- apply(t(apply(samples, 1, FUN = function(x) { x == 2 })), 1, function(x) sum(x) )
n.threes <- apply(t(apply(samples, 1, FUN = function(x) { x == 3 })), 1, function(x) sum(x) )

sum((n.ones == 1 & n.twos == 1 & n.threes == 1) == T)
```

No, 3 != 6.

d.) Is the probability of obtaining a bootstrap sample with one 1 and two 3's the same as the probabiliity of obtaining a bootstrap sample with each of 1, 2 and 3 occuring exactly once?

```{r, echo = T}

( sum((n.ones == 1 & n.threes == 2)) / n ) == ( sum((n.ones == 1 & n.twos == 1 &  n.threes == 1)) / n )

```

No, 3% and 6% chances respectfully.

### 5.4

Consider the samples 1, 3, 3, and 5 from some distribution.

```{r}
samples <- c(1, 3, 3, 5)
```

a.) How many bootstrap samples are there?

```{r}
boot <- permutations(n = 3, r = 4, v = samples, repeats.allowed = T)

n <- nrow(boot)
```

_3 unique items to pick from, 4 places to put each item._

Number of permutations: *$3^4$ = `r n`*

b.) List the distinct bootstrap samples assuming order does not matter.

```{r}
combinations(n = 3, r = 4, v = samples, repeats.allowed = T)

choose(4 + 3 - 1, 4)
```

### 5.5

We determine the number of distinct bootstrap samples from a finite set.

a.) A bakery sells five types of cookies: sugar, chocolate chip, oatmeal, peanut butter, and ginger snap. Show that the number of ways to order 5 cookies is $9 \choose 5$

Unordered samping with replacement: $n + k - 1 \choose k$, $n = 5, k = 5$

```{r}
choose(5 + 5 - 1, 5)
```

b.) Show that the number of sets of size n (order does not matter) drawn with replacement from the (distinct) $a_1, a_2, \ldots, a_n$ is ${2n-1}\choose n$

Conclude that the number of distinct bootstrap samples from the set $[a_1, a_2, \ldots, a_n]$ is ${2n - 1} \choose  n$

### 5.6

Let $k_1, k_2, \ldots, k_n$ denote non-negative integers satisfying $k_1 + k_2 + \ldots + k_n = n$, and suppose the elements in the set $a_1, a_2, \ldots, a_n$ are distinct.

a.) Show that the number of bootstrap samples with $k_1$ occurrences of $a_1, k_2$ occurrences of $a_2, \ldots, k_n$ occurrences of $a_n$ is $n \choose k_1, k_2, \ldots, k_n$

b.) Compute the probability that a randomly drawn bootstrap sample will have $k_i$ occurrences of $a_i, i = 1, 2, \ldots, n$

### 5.7

Refer to Example 5.4 and the remark at the end of the example.

a.) What might account for the fact that there were more missing values for the men who skateboarded in front of the male experimenter? How might this bias the outcome?

_It could be that the approached skateboarders refused to participate in the study of performing tricks in front of other men._

b.) Why do you suppose it was important that the two experimenters were blinded to the purpose of the study?

_The female could have flurted or otherwise influenced skateboarders who were performing tricks if they knew the intent of the study._

### 5.8

Consider a population that has a normal distribution with mean $\mu = 36$, standard deviation $\sigma = 8$.

```{r}
mu <- 36; sigma <- 8; n <- 200

se <- mu / sqrt(n)
```

a.) The sampling distribution of $\bar{X}$ for samples of size 200 will have what mean, standard error, and shape?

_$\mu = 36$, SE = 36 / sqrt(200) = `r se`, shape will be approximately normal (CLT)._

b.) Use R to draw a random sample of size 200 from this population. Conduct EDA on your sample.

```{r}
set.seed(123)

samp <- data.table(values = rnorm(200, mean = 36, sd = 8))

ggplot(samp, aes(values)) +
   geom_histogram(aes(y = ..density.., fill = ..count..), bins = 30) +
   geom_density(aes(values), color = "darkorange") +
   geom_vline(xintercept = mu, col = "black", lty = 2) +
   geom_vline(xintercept = mu - se, col = "darkred", lty = 2) +
   geom_vline(xintercept = mu + se, col = "darkred", lty = 2)

```

c.) Compute the bootstrap distribution for your sample, and note the bootstrap mean and standard error.

```{r}

boot.fn <- function(data, index){
   mean(data[index]$values)
}

I <- 10e3

boot(samp, boot.fn, R = I) # boot pkg

cst.boot <- function(values, n, I = 10e3, alpha = 0.05) {
   bootstrap <- numeric(I)
   
   for(i in 1:I)
   {
      bootstrap[i] <- mean( sample(values, n, replace = T) )
   }
   
   observed <- mean(values)
   
   boot.mean <- mean(bootstrap)
   boot.bias <- observed - boot.mean
   boot.se <- sd(bootstrap)
   
   list(bootstrap = bootstrap,
         observed = observed,
         mean = boot.mean,
         bias = boot.bias,
         se = boot.se,
         conf = quantile(bootstrap, c(alpha/2, 1 - alpha/2)))
}

```

d.) Compare the bootstrap distribution to the theoretical sampling distribution by creating a table like Table 5.2:

```{r}
n.200 <- cst.boot(samp$values, 200)

tbl <- data.table(Data = c("Population", "Sampling Distribution", "Sample", "Bootstrap Distribution"),
                  Mean = c(mu, mu, n.200$observed, n.200$mean),
                  SD = c(sigma, mu/sqrt(n), sd(samp$values), n.200$se))

pretty_kable(tbl, "Sampling Statistics")
```

e.) Repeat for sample sizes $n = 50$ and $n = 10$. Carefully describe yyour observations about the effects of sample size on the bootstrap distribuiton.

```{r}
n <- 50
samp <- data.table(values = rnorm(n, mean = mu, sd = sigma))
n.50 <- cst.boot(samp$values, n)

tbl <- data.table(Data = c("Population", "Sampling Distribution", "Sample", "Bootstrap Distribution"),
                  Mean = c(mu, sigma, n.50$observed, n.50$mean),
                  SD = c(sigma, mu/sqrt(n), sd(samp$values), n.50$se))

pretty_kable(tbl, "Sampling Statistics")

```

```{r}
n <- 10
samp <- data.table(values = rnorm(n, mean = mu, sd = sigma))
n.10 <- cst.boot(samp$values, 10)

tbl <- data.table(Data = c("Population", "Sampling Distribution", "Sample", "Bootstrap Distribution"),
                  Mean = c(mu, sigma, n.10$observed, n.10$mean),
                  SD = c(sigma, mu/sqrt(n), sd(samp$values), n.10$se))

pretty_kable(tbl, "Sampling Statistics")
```

_The center of the bootstrap distribution doesn't vary much with smaller n, however, confidence intervals (the sd of the bootstrap dist) vary wildy._

### 5.9

Consider a population that has a gamma distribution with parameters r = 5, $\lambda = 4$.

a.) Use simulation (with $n = 200$) to generate an approximate sampling distribution of the mean; plot and describe the distribution.

```{r}
set.seed(123)

n <- 200; r <- 5; lambda <- 4; mu <- lambda/r

pop <- data.table(values = rgamma(n, shape = lambda, rate = r))

ggplot(pop, aes(values)) +
   geom_histogram(aes(y = ..density.., fill = ..count..), bins = 30) +
   geom_density(aes(values), col = "darkorange")
```

b.) Now, draw one random sample of size 200 from this population. Create a histogram of your sample, and find the mean and standard deviation.

```{r}
samp <- data.table(values = sample(pop$values, n, replace = T))

ggplot(samp, aes(values)) +
   geom_histogram(aes(y = ..density.., fill = ..count..), bins = 30) +
   geom_density(aes(values), col = "darkorange")

xbar <- mean(samp$values); sd <- sd(samp$values) 

xbar; sd
```

c.) Compute the bootstrap distribution of the mean for you sample, plot it, and note the bootstrap mean and standard error.

```{r}
I <- 10e3

boot.fn <- function(data, index) {
   mean(data[index]$values)
}

boot(samp, boot.fn, R = I)

n.200 <- cst.boot(samp$values, n)

ggplot(data.table(values = n.200$bootstrap), aes(values)) +
   geom_histogram(aes(y = ..density.., fill = ..count..), bins = 30) +
   geom_density(aes(values), col = "darkorange") +
   labs(title = "N=200, bootstrapped mean (Gamma r=5, lambda = 4)")
```

d.) Compare the bootstrap distribution to the approximate theoretical sampling distribution by creating a table like Table 5.2.

```{r}
tbl <- data.table(Data = c("Population", "Sampling Distribution", "Sample", "Bootstrap Distribution"),
                  Mean = c(mu, sd(samp$values), n.200$observed, n.200$mean),
                  SD = c(mu, mu/sqrt(n), sd(samp$values), n.200$se))

pretty_kable(tbl, "Sampling Statistics")
```

e.) Repeat (a-e) for sample sizes of n = 50, and n = 10. Describe carefully your observations about the effects of sample size on the bootstrap distribution.

```{r}
n <- 50

pop <- data.table(values = rgamma(n, shape = lambda, rate = r))

ggplot(pop, aes(values)) +
   geom_histogram(aes(y = ..density.., fill = ..count..), bins = 30) +
   geom_density(aes(values), col = "darkorange")

samp <- data.table(values = sample(pop$values, n, replace = T))

ggplot(samp, aes(values)) +
   geom_histogram(aes(y = ..density.., fill = ..count..), bins = 30) +
   geom_density(aes(values), col = "darkorange")

xbar <- mean(samp$values); sd <- sd(samp$values) 

xbar; sd

n.50 <- cst.boot(samp$values, n)

ggplot(data.table(values = n.50$bootstrap), aes(values)) +
   geom_histogram(aes(y = ..density.., fill = ..count..), bins = 30) +
   geom_density(aes(values), col = "darkorange") +
   labs(title = "N=50, bootstrapped mean (Gamma r=5, lambda = 4)")

tbl <- data.table(Data = c("Population", "Sampling Distribution", "Sample", "Bootstrap Distribution"),
                  Mean = c(mu, sd(samp$values), n.50$observed, n.50$mean),
                  SD = c(mu, mu/sqrt(n), sd(samp$values), n.50$se))

pretty_kable(tbl, "Sampling Statistics")
```


```{r}
n <- 10

pop <- data.table(values = rgamma(n, shape = lambda, rate = r))

ggplot(pop, aes(values)) +
   geom_histogram(aes(y = ..density.., fill = ..count..), bins = 30) +
   geom_density(aes(values), col = "darkorange")

samp <- data.table(values = sample(pop$values, n, replace = T))

ggplot(samp, aes(values)) +
   geom_histogram(aes(y = ..density.., fill = ..count..), bins = 30) +
   geom_density(aes(values), col = "darkorange")

xbar <- mean(samp$values); sd <- sd(samp$values) 

xbar; sd

n.50 <- cst.boot(samp$values, n)

ggplot(data.table(values = n.50$bootstrap), aes(values)) +
   geom_histogram(aes(y = ..density.., fill = ..count..), bins = 30) +
   geom_density(aes(values), col = "darkorange") +
   labs(title = "N=50, bootstrapped mean (Gamma r=5, lambda = 4)")

tbl <- data.table(Data = c("Population", "Sampling Distribution", "Sample", "Bootstrap Distribution"),
                  Mean = c(mu, sd(samp$values), n.50$observed, n.50$mean),
                  SD = c(mu, mu/sqrt(n), sd(samp$values), n.50$se))

pretty_kable(tbl, "Sampling Statistics")
```

### 5.10

We investigate the bootstrap distribution of the median. Create random sample of size n for various n and bootstrap the median. Describe the bootstrap distribution.

```{r}
ne <- 14 # n even
no <- 15 # n odd

wwe <- rnorm(ne) # draw samples of size ne
wwo <- rnorm(no) # draw random samples of size no

N <- 10^4

even.boot <- numeric(N) # save space
odd.boot <- numeric(N)

for(i in 1:N)
{
   x.even <- sample(wwe, ne, replace = T)
   x.odd <- sample(wwo, no, replace = T)
   
   even.boot[i] <- median(x.even)
   odd.boot[i] <- median(x.odd)
}

boot <- data.table(even = even.boot, odd = odd.boot)

p1 <- ggplot(boot, aes(even)) +
   geom_histogram(aes(y = ..density.., fill = ..count..), bins = 30) +
   geom_density(aes(even), col = "darkorange") +
   labs(title = "even")

p2 <- ggplot(boot, aes(odd)) +
   geom_histogram(aes(y = ..density.., fill = ..count..), bins = 30) +
   geom_density(aes(even), col = "darkorange") +
   labs(title = "odd")

gridExtra::grid.arrange(p1, p2)
```

Change the sample sizes to 36 and 37; 200 and 201; and 10,000 and 10,001.

Note the similarities/dissimalarities, trends, and so on. Why does the parity of the sample size matter? (_Note: Adjust the x limits in the plots as needed._)

```{r}
ne <- 36 # n even
no <- 37 # n odd

wwe <- rnorm(ne) # draw samples of size ne
wwo <- rnorm(no) # draw random samples of size no

N <- 10^4

even.boot <- numeric(N) # save space
odd.boot <- numeric(N)

for(i in 1:N)
{
   x.even <- sample(wwe, ne, replace = T)
   x.odd <- sample(wwo, no, replace = T)
   
   even.boot[i] <- median(x.even)
   odd.boot[i] <- median(x.odd)
}

boot <- data.table(even = even.boot, odd = odd.boot)

p1 <- ggplot(boot, aes(even)) +
   geom_histogram(aes(y = ..density.., fill = ..count..), bins = 30) +
   geom_density(aes(even), col = "darkorange")

p2 <- ggplot(boot, aes(odd)) +
   geom_histogram(aes(y = ..density.., fill = ..count..), bins = 30) +
   geom_density(aes(even), col = "darkorange")

gridExtra::grid.arrange(p1, p2)
```

```{r}
ne <- 200 # n even
no <- 201 # n odd

wwe <- rnorm(ne) # draw samples of size ne
wwo <- rnorm(no) # draw random samples of size no

N <- 10^4

even.boot <- numeric(N) # save space
odd.boot <- numeric(N)

for(i in 1:N)
{
   x.even <- sample(wwe, ne, replace = T)
   x.odd <- sample(wwo, no, replace = T)
   
   even.boot[i] <- median(x.even)
   odd.boot[i] <- median(x.odd)
}

boot <- data.table(even = even.boot, odd = odd.boot)

p1 <- ggplot(boot, aes(even)) +
   geom_histogram(aes(y = ..density.., fill = ..count..), bins = 30) +
   geom_density(aes(even), col = "darkorange")

p2 <- ggplot(boot, aes(odd)) +
   geom_histogram(aes(y = ..density.., fill = ..count..), bins = 30) +
   geom_density(aes(even), col = "darkorange")

gridExtra::grid.arrange(p1, p2)
```

```{r}
ne <- 10000 # n even
no <- 10001 # n odd

wwe <- rnorm(ne) # draw samples of size ne
wwo <- rnorm(no) # draw random samples of size no

N <- 10^4

even.boot <- numeric(N) # save space
odd.boot <- numeric(N)

for(i in 1:N)
{
   x.even <- sample(wwe, ne, replace = T)
   x.odd <- sample(wwo, no, replace = T)
   
   even.boot[i] <- median(x.even)
   odd.boot[i] <- median(x.odd)
}

boot <- data.table(even = even.boot, odd = odd.boot)

p1 <- ggplot(boot, aes(even)) +
   geom_histogram(aes(y = ..density.., fill = ..count..), bins = 30) +
   geom_density(aes(even), col = "darkorange")

p2 <- ggplot(boot, aes(odd)) +
   geom_histogram(aes(y = ..density.., fill = ..count..), bins = 30) +
   geom_density(aes(even), col = "darkorange")

gridExtra::grid.arrange(p1, p2)
```

For odd n, median will be one of the sample points. For smaller n, there will be only n possible values for the median, so the sampling distribution is more "granular" than when n is even.

### 5.11

Import the data from data set Bangladesh. In addition to aresnic concentrations for 271 wells, the data set contains cobolt and chlorine concentrations.

a.) Conduct EDA on the chlorine concentrations and describe the salient features.

```{r}
Bangladesh <- data.table(read.csv(paste0(data.dir, "Bangladesh.csv"),
                                 header = T))

head(Bangladesh)

ggplot(Bangladesh, aes(Chlorine)) +
   geom_histogram(aes(y = ..density.., fill = ..count..), bins = 30) +
   geom_density(aes(Chlorine), col = "darkorange")

GGally::ggpairs(Bangladesh)
```

b.) Bootstrap the mean.

```{r}
N <- 10e3

boot.fn <- function(data, index){
   mean(data[index], na.rm = T)
}

boot(Bangladesh$Chlorine, boot.fn, R = N)

observed <- mean(Bangladesh$Chlorine, na.rm = T)

bootstrap <- numeric(N)

for(i in 1:N)
{
   bootstrap[i] <- mean(sample(Bangladesh$Chlorine, size = nrow(Bangladesh), replace = T), na.rm = T)   
}

ggplot(data.table(values = bootstrap), aes(values)) +
   geom_histogram(aes(y = ..density.., fill = ..count..), bins = 30) +
   geom_density(aes(values), col = "darkorange")
```

c.) Find and interpret the 95% bootstrap percentile confidence interval.

```{r}
alpha <- 0.05
quantile(bootstrap, c(alpha/2, 1 - alpha/2))
```

The spread on the confidence interval is extremely large, which is unsuprising given the heavly skewed distribtion of the sample.

d.) What is the bootstrap estimate of the bias? What fraction of the bootstrap standard error does it represent?

```{r}
bias <- observed - mean(bootstrap)

sd(bootstrap) / bias
```
