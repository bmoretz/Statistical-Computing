---
title: ''
mainfont: Arial
fontsize: 12pt
documentclass: report
header-includes:
- \PassOptionsToPackage{table}{xcolor}
- \usepackage{caption}
- \usepackage{amssymb}
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{wrapfig}
- \usepackage{float}
- \usepackage{colortbl}
- \usepackage{pdflscape}
- \usepackage{tabu}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage[normalem]{ulem}
- \usepackage{makecell}
- \usepackage[table]{xcolor}
- \usepackage{fancyhdr}
- \usepackage{boldline}
- \usepackage{tipa}
   \definecolor{headergrey}{HTML}{545454}
   \definecolor{msdblue}{HTML}{1C93D1}
   \pagestyle{fancy}
   \setlength\headheight{30pt}
   \rhead{\color{headergrey}\today}
   \fancyhead[L]{\color{headergrey}Moretz, Brandon}
   \fancyhead[C]{\Large\bfseries\color{headergrey}Spam Identification}
   \rfoot{\color{headergrey}Chapter 3}
   \lfoot{\color{headergrey}}
   \fancyfoot[C]{\rmfamily\color{headergrey}Case Studies In Data Science}
geometry: left = 1cm, right = 1cm, top = 2cm, bottom = 3cm
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    fig_caption: yes
    latex_engine: xelatex
editor_options: 
  chunk_output_type: console
---


```{r knitr_setup, include = FALSE}

knitr::opts_chunk$set(
   echo = T, 
   eval = TRUE, 
   dev = 'png', 
   fig.width = 9, 
   fig.height = 4.5)

options(knitr.table.format = "latex")

```

```{r report_setup, message = FALSE, warning = FALSE, include = FALSE}

library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(dplyr, quietly = TRUE, warn.conflicts = FALSE)
library(ggthemes, quietly = TRUE, warn.conflicts = FALSE)
library(scales, quietly = TRUE, warn.conflicts = FALSE)

library(knitr, quietly = TRUE, warn.conflicts = FALSE)
library(kableExtra, quietly = TRUE, warn.conflicts = FALSE)
library(pander, quietly = TRUE, warn.conflicts = FALSE)
library(formattable, quietly = TRUE, warn.conflicts = FALSE)

library(grid, quietly = TRUE, warn.conflicts = FALSE)
library(gridExtra, quietly = TRUE, warn.conflicts = FALSE)
library(extrafont, quietly = TRUE, warn.conflicts = FALSE)
library(tinytex, quietly = TRUE, warn.conflicts = FALSE)

library(here, quietly = TRUE, warn.conflicts = FALSE)

library(codetools, quietly = TRUE, warn.conflicts = FALSE)
library(lattice, quietly = TRUE, warn.conflicts = FALSE)
library(fields, quietly = TRUE, warn.conflicts = FALSE)
library(RColorBrewer, quietly = TRUE, warn.conflicts = FALSE)
library(tm, quietly = TRUE, warn.conflicts = FALSE)

library(rbenchmark, quietly = TRUE, warn.conflicts = FALSE)

library(rpart, quietly = TRUE, warn.conflicts = FALSE)
library(rpart.plot, quietly = TRUE, warn.conflicts = FALSE)

options(tinytex.verbose = TRUE)
suppressMessages(library("tidyverse"))

pretty_kable <- function(data, title, dig = 2) {
  kable(data, caption = title, digits = dig) %>%
    kable_styling(bootstrap_options = c("striped", "hover")) %>%
      kableExtra::kable_styling(latex_options = "hold_position")
}

theme_set(theme_light())

# Theme Overrides
theme_update(axis.text.x = element_text(size = 10),
             axis.text.y = element_text(size = 10),
             plot.title = element_text(hjust = 0.5, size = 16, face = "bold", color = "darkgreen"),
             axis.title = element_text(face = "bold", size = 12, colour = "steelblue4"),
             plot.subtitle = element_text(face = "bold", size = 8, colour = "darkred"),
             legend.title = element_text(size = 12, color = "darkred", face = "bold"),
             legend.position = "right", legend.title.align=0.5,
             panel.border = element_rect(linetype = "solid", 
                                         colour = "lightgray"), 
             plot.margin = unit(c( 0.1, 0.1, 0.1, 0.1), "inches"))

data.dir <- file.path(here::here(), "Case Studies", "datasets", "spam")

```

```{r pander_setup, include = FALSE}

knitr::opts_chunk$set(comment = NA)

panderOptions('table.alignment.default', function(df)
    ifelse(sapply(df, is.numeric), 'right', 'left'))
panderOptions('table.split.table', Inf)
panderOptions('big.mark', ",")
panderOptions('keep.trailing.zeros', TRUE)

```

# Using Statistics to Identify Spam

## Anatomy of an email Message

### Spam Data

```{r}

head(list.files(path = file.path(data.dir, "easy_ham")))
head(list.files(path = file.path(data.dir, "spam_2")))

directories <- paste(data.dir, list.files(data.dir), sep = .Platform$file.sep)

file_counts <- sapply(directories, function(dir) length(list.files(dir)))

total_files <- sum(file_counts)
total_files
```

```{r}
file_counts

idx <- c(1:5, 15, 27, 68, 69, 329, 404, 427, 516, 852, 971)

fn <- list.files(directories[1], full.names = T)[idx]

sampleEmail <- sapply(fn, readLines)
```

### Text Mining and Naive Bayes Classification

```{r}
msg <- sampleEmail[[1]]
which(msg == "")[1]

match("", msg)

splitPoint <- match("", msg)

msg[ (splitPoint - 2):(splitPoint + 6)]

header <- msg[1:(splitPoint - 1)]
body <- msg[ -(1:splitPoint) ]

```


```{r}

splitMessage <- function(msg) {
   splitPoint <- match("", msg)
   
   header <- msg[ 1:(splitPoint - 1)]
   body <- msg[ -(1:splitPoint)]
   
   return(list(header = header, body = body))
}

sampleSplit <- lapply(sampleEmail, splitMessage)

header <- sampleSplit[[1]]$header
grep("Content-Type", header)
grep("multi", tolower(header))

header[46]

headerList <- lapply(sampleSplit, function(msg) msg$header)

CTloc <- sapply(headerList, grep, pattern = "Content-Type")

sapply(headerList, function(header) {
   CTloc <- grep("Content-Type", header)
   if( length(CTloc) == 0) return(NA)
   CTloc
})

hasAttach <- sapply(headerList, function(header) {
   CTloc <- grep("Content-Type", header)
   
   if(length(CTloc) == 0) return(F)
   grepl("multi", tolower(header[CTloc]))
})

hasAttach

header <- sampleSplit[[6]]$header
boundaryIdx <- grep("boundary=", header)
header[boundaryIdx]

sub(".*boundary=\"(.*)\";.*", "\\1", header[boundaryIdx])

header2 <- headerList[[9]]
boundaryIdx2 <- grep("boundary=", header2)
header2[boundaryIdx2]

sub('.*boundary="(.*)";.*', "\\1", header2[boundaryIdx2])

boundary2 <- gsub('"', "", header2[boundaryIdx2])

sub(".*boundary= *(.*);?.*", "\\1", boundary2)

boundary <- gsub('"', "", header[boundaryIdx])
sub(".*boundary= *(.*);?.*", "\\1", boundary)

```

```{r}

getBoundary <- function(header) {
   boundaryIdx <- grep("boundary=", header)
   boundary = gsub('"', "", header[boundaryIdx])
   gsub(".*boundary= *([^;]*);?.*", "\\1", boundary)
}

```

```{r}

boundary <- getBoundary(headerList[[15]])
body <- sampleSplit[[15]]$body

bString <- paste("--", boundary, sep = "")
bStringLocs <- which(bString == body)
bStringLocs

eString <- paste("--", boundary, "--", sep = "")
eStringLoc <- which(eString == body)
eStringLoc

msg <- body[ (bStringLocs[1] + 1) : (bStringLocs[2] - 1)]
tail(msg)

msg <- c(msg, body[ (eStringLoc + 1) : length(body) ])
tail(msg)

```

### Handle Attachments

```{r}


```

### Extracting Words from the Message Body

```{r}
head(sampleSplit[[1]]$body)

msg <- sampleSplit[[3]]$body
head(msg)

```

### Stemming

```{r}
exclude_word_list <- stopwords(kind = "en")
```

### Convert To Wordlist

```{r}
tolower(gsub("[[:punct:]0-9[:blank:]]+", " ", msg))

msg[ c(1, 3, 26, 27) ]

cleanMsg <- tolower(gsub("[[:punct:]0-9[:blank:]]+", " ", msg))
cleanMsg[ c(1, 3, 26, 27) ]

words <- unlist(strsplit(cleanMsg, "[[:blank:]]+"))

words <- words[ nchar(words) > 1 ]

words <- words[ ! (words %in% exclude_word_list) ]

head(words)

```

```{r}

findMsgWords <- function(msg, exclude) {
   
   cleanMsg <- tolower(gsub("[[:punct:]0-9[:blank:]]+", " ", msg))

   words <- unlist(strsplit(cleanMsg, "[[:blank:]]+"))
   
   keep <- sapply(words, function(word) return(!(word %in% exclude)))
   
   
   return(words[ keep ])   
}

```

### Prep Wrap-Up

```{r}

dropAttach <- function(body, boundary) {
   
   if(is.null(body)) {
      return("")
   }
   
   bString <- paste("--", boundary, sep = "")
   bStringLocs <- which(bString == body)
   
   eString <- paste("--", boundary, "--", sep = "")
   eStringLoc <- which(eString == body)
   
   if(length(bStringLocs) == 2) {
      msg <- body[ (bStringLocs[1] + 1) : (bStringLocs[2] - 1)]
   }
   
   if(length(eStringLoc) > 0) {
      msg <- c(msg, body[ (eStringLoc + 1) : length(body) ])
   }
   
   return(msg)
}

processAllWords <- function(dirName, stopWords) {
   # read all files in the directory
   fileNames <- list.files(dirName, full.names = T)
   
   # drop files that are not email, i.e., cmds
   notEmail <- grep("cmds$", fileNames)
   
   if( length(notEmail) > 0) fileNames <- fileNames[ -notEmail ]
   
   messages <- lapply(fileNames, readLines, encoding = "latin1")
   
   # split header and body
   emailSplit <- lapply(messages, splitMessage)
   
   # put body and header in own lists
   bodyList <- lapply(emailSplit, function(msg) msg$body)
   headerList <- lapply(emailSplit, function(msg) msg$header)
   rm(emailSplit)
   
   # determine which messages have attachments
   hasAttach <- sapply(headerList, function(header) {
      
      CTloc <- grep("Content-Type", header)
      
      if( length(CTloc) == 0) return(0)
      
      multi <- grep("multi", tolower(header[CTloc]))
      
      if( length(multi) == 0 ) return(0)
      
      multi
   })
   
   hasAttach <- which(hasAttach > 0)
   
   # find boundary string for messages with attachments
   boundaries <- sapply(headerList[hasAttach], getBoundary)
   
   # drop attachments from message body
   bodyList[hasAttach] <- mapply(dropAttach, bodyList[hasAttach],
                                 boundaries, SIMPLIFY = F)
   
   # extract words from body
   msgWordsList <- lapply(bodyList, findMsgWords, stopWords)
   
   invisible(msgWordsList)
}

```

### Build Email Database

```{r}

msgWordList <- lapply(directories, processAllWords, stopWords = exclude_word_list)

numMsgs <- sapply(msgWordList, length)
numMsgs

isSpam <- c(rep(FALSE, numMsgs[1]), 
            rep(FALSE, numMsgs[2]), 
            rep(FALSE, numMsgs[3]), 
            rep(TRUE, numMsgs[4]),
            rep(TRUE, numMsgs[5]))

msgWordsList <- unlist(msgWordList, recursive = F)

```

## Naive Bayes Classifier Implementation

### Train / Test Split

```{r}

numEmail <- length(isSpam)

numSpam <- sum(isSpam)
numHam <- numEmail - numSpam

set.seed(418910)

testSpamIdx <- sample(numSpam, size = floor(numSpam/3))
testHamIdx <- sample(numHam, size = floor(numHam/3))

testMsgWords <- c((msgWordsList[isSpam])[testSpamIdx],
                  (msgWordsList[!isSpam])[testHamIdx])

trainMsgWords <- c((msgWordsList[isSpam])[ - testSpamIdx ],
                   (msgWordsList[!isSpam])[ - testHamIdx])

testIsSpam <- rep(c(T, F), 
                  c(length(testSpamIdx), length(testHamIdx)))

trainIsSpam <- rep(c(T, F),
                   c(numSpam - length(testSpamIdx),
                     numHam - length(testHamIdx)))

```

### Probability Estimates from Training Sample

```{r}
bow <- unique(unlist(trainMsgWords))

length(bow)
```

```{r}
spamWordCounts <- rep(0, length(bow))

names(spamWordCounts) = bow

tmp <- lapply(trainMsgWords[trainIsSpam], unique)
tt <- table( unlist(tmp) )
spamWordCounts[ names(tt) ] = tt

spamWordsProbs <- (spamWordCounts + 0.5) / (sum(trainIsSpam) + 0.5)

spamWordsProbs[1:20]

hamWordCounts <- rep(0, length(bow))

names(hamWordCounts) = bow

tmp <- lapply(trainMsgWords[ - trainIsSpam], unique)
tt <- table( unlist(tmp) )
hamWordCounts[ names(tt) ] = tt

hamWordsProbs <- (hamWordCounts + 0.5) / (sum(!trainIsSpam) + 0.5)

probs <- log(spamWordsProbs) - log(hamWordsProbs)

head(probs)
```

```{r}
wordsList <- trainMsgWords
spam <- trainIsSpam

make_words_valid_columns <- function( words, all_words ) {
   
   word_counts <- rep(0, length(all_words))
   names(word_counts) <- all_words
   
   tmp <- lapply(words, unique)
   tt <- table( unlist(tmp) )
   word_counts[ names(tt) ] = tt

   return(word_counts)
}

computeFreqs <- function(wordsList, spam, bow = unique(unlist(wordsList))) {
   
   all_words <- unique(bow)
   
   # create a matrix for spam, ham, and log odds
   wordTable <- matrix(0.5, nrow = 2, ncol = length(bow))
   colnames(wordTable) <- all_words
   rownames(wordTable) <- c( "presentLogOdds",
                          "absentLogOdds")
   
   # for each spam message, add 1 to the counts for words in messsage
   
   spam_all <- wordsList[spam]
   spam_words <- make_words_valid_columns( spam_all, all_words )

   wordTable <- rbind(wordTable, spam_words + 0.5)
   rownames(wordTable)[3] <- "spam"
   
   # Similarly for ham messages
   
   ham_all <- wordsList[ !spam ]
   
   ham_words <- make_words_valid_columns( ham_all, all_words )
   
   wordTable <- rbind(wordTable, ham_words + 0.5)
   rownames(wordTable)[4] <- "ham"
   
   head(wordTable[, 1:20])
   
   # find the total number of spam and ham
   numSpam <- sum(spam)
   numHam <- length(spam) - numSpam
   
   # prob (word|spam) and prob(words|ham)
   wordTable["spam", ] <- wordTable["spam", ] / (numSpam + 0.5)
   wordTable["ham", ] <- wordTable["ham", ] / (numHam + 0.5)
   
   head(wordTable[, 1:20])
   
   # log odds
   wordTable["presentLogOdds", ] = 
      log(wordTable["spam", ]) - log(wordTable["ham", ])
   
   wordTable["absentLogOdds", ] =
      log((1 - wordTable["spam", ])) - log((1 - wordTable["ham", ]))
   
   invisible(wordTable)
}

```

```{r}
trainTable <- computeFreqs(trainMsgWords, trainIsSpam)

# peek the prob table
head(trainTable[, 1:10])
```

### Classifying New Messages

```{r}
newMsg <- testMsgWords[[1]]

# only look at words we have classified
newMsg <- newMsg[ !is.na(match(newMsg, colnames(trainTable)))]

present <- colnames(trainTable) %in% newMsg

sum( trainTable["presentLogOdds", present]) +
   sum( trainTable["absentLogOdds", !present])

newMsg <- testMsgWords[[ which(!testIsSpam)[ 1 ] ]]
newMsg <- newMsg[ !is.na(match(newMsg, colnames(trainTable)))]
present <- (colnames(trainTable) %in% newMsg)

sum(trainTable["presentLogOdds", present]) +
   sum(trainTable["absentLogOdds", !present])

```

```{r}

computeMsgLLR <- function(words, freqTable) {
   
   # discard words not in training data
   words <- words[!is.na(match(words, colnames(freqTable)))]
   
   # Find which words are present
   present <- colnames(freqTable) %in% words
   
   sum(freqTable["presentLogOdds", present]) +
      sum(freqTable["absentLogOdds", !present])
}

```

```{r}
testLLR <- sapply(testMsgWords, computeMsgLLR, trainTable)
```

```{r}
tapply(testLLR, testIsSpam, summary)
```

```{r}
results_df <- data.table( score = testLLR, class = testIsSpam )

ggplot(results_df, aes(score, class, fill = class)) +
   geom_boxplot() +
   coord_flip()   
```

```{r}
typeIErrorRate <- function(tau, llrVals, spam) {
   classify <- llrVals > tau
   sum(classify & !spam) / sum(!spam)
}

typeIErrorRate(0, testLLR, testIsSpam)
typeIErrorRate(-20, testLLR, testIsSpam)

error_rates <- sapply(seq(-30, 30, 1), function(cutoff) c(cutoff = cutoff, rate = typeIErrorRate(cutoff, testLLR, testIsSpam)))

er_df <- data.table(t(error_rates))

ggplot(er_df, aes(cutoff, rate)) +
   geom_line(col = "darkblue") +
   labs(title = "False Positive Error Rates")
```

```{r}
typeIErrorRates <- function(llrVals, isSpam) {
   o <- order(llrVals)
   llrVals <- llrVals[o]
   isSpam <- isSpam[o]
   
   idx <- which(!isSpam)
   N <- length(idx)
   list(error = (N:1)/N, values = llrVals[idx])
}


```

### Computational Considerations

```{r}
smallNums <- rep((1/2)^40, 2000000)
largeNum <- 10000

print(sum(smallNums), digits = 20)

print(largeNum + sum(smallNums), digits = 20)

for(i in 1:length(smallNums)) {
   largeNum <- largeNum + smallNums[i]
}

print(largeNum, digits = 20)
```

## Recursive Partitioning and Classification Trees

### Revised E-mail Data Structure

```{r}
header <- sampleSplit[[1]]$header

header[1:12]

header[1] = sub("^From", "Top-From:", header[1])

headerPieces <- read.dcf(textConnection(header), all = T)

headerPieces[, "Delivered-To"]

headerVec <- unlist(headerPieces)
dupKeys <- sapply(headerPieces, function(x) length(unlist(x)))
names(headerVec) <- rep(colnames(headerPieces), dupKeys)

headerVec[ which(names(headerVec) == "Delivered-To") ]

length(headerVec)

length(unique(names(headerVec)))
```

```{r}
processHeader <- function(header) {
   # modify the first line to create a key:value pair
   header[1] <- sub("^From", "Top-From:", header[1])
   
   headerMat <- read.dcf(textConnection(header), all = T)
   headerVec <- unlist(headerMat)
   
   dupKeys <- sapply(headerMat, function(x) length(unlist(x)))
   names(headerVec) <- rep(colnames(headerMat), dupKeys)
   
   return(headerVec)
}

headerList <- lapply(sampleSplit,
                     function(msg) {
                        processHeader(msg$header)
                     })

contentTypes <- sapply(headerList, function(header)
   header["Content-Type"])

names(contentTypes) <- NULL

contentTypes
```

#### Attachments Revisited

```{r}
hasAttach <- grep("^ *multi", tolower(contentTypes))
hasAttach

boundaries <- getBoundary(contentTypes[ hasAttach ])
boundaries

boundary <- boundaries[9]
body <- sampleSplit[[15]]$body

bString <- paste("--", boundary, sep = "")
bStringLocs <- which(bString == body)
bStringLocs

eString <- paste("--", boundary, "--", sep = "")
eStringLoc <- which(eString == body)
eStringLoc

range <- diff(c(bStringLocs[-1], eStringLoc))

body[1:range]

```

```{r}

processAttach <- function(body, contentType ) {

   boundary <- getBoundary(contentType)

   bString <- paste("--", boundary, sep = "")
   bStringLocs <- which(bString == body)

   eString <- paste("--", boundary, "--", sep = "")
   eStringLoc <- which(eString == body)
   
   n <- length(body)
   
   if(length(bStringLocs) == 2) {
      
      bodyContent <- body[(bStringLocs[1] + 2):(bStringLocs[2] - 1)]

      emptyLines <- which(bodyContent == "")
      bodyContent <- bodyContent[ - emptyLines]
    
      attachContent <- body[(bStringLocs[2] + 1):n]
      
      aLen <- diff(c(bStringLocs[-1], eStringLoc))
      aType <- body[bStringLocs[-1] + 1]
      
      if(length(aLen) == length(aType)) {      
         attachments <- data.frame(aLen = aLen, aType = aType)
      } else {
         attachments <- data.frame(aLen = c(), aType = c())
      }
      
   } else {
      if( length(bStringLocs) == 0 ) {
         bodyContent <- body
      } else {
         bodyContent = body
      }
      attachments <- data.frame(aLen = c(), aType = c())
   }
   
   return(list(body = bodyContent, attachDF = attachments ))
}

```

#### More E-Mails

```{r}

bodyList <- lapply(sampleSplit, function(msg) msg$body)
attList <- mapply(processAttach, bodyList[hasAttach],
                  contentTypes[hasAttach], SIMPLIFY = F)

lens <- sapply(attList, function(processedA)
                           processedA$attachDF$aLen)
```

```{r}
readEmail <- function(dirName) {
   # retrieve the names of files in the directory
   fileNames <- list.files(dirName, full.names = T)
   
   # drop files that are not email
   notEmail <- grep("cmds$", fileNames)
   
   if( length(notEmail) > 0 ) fileNames = fileNames[ - notEmail ]
   
   # read all files in the directory
   lapply(fileNames, readLines, encoding = "latin1")
}

processAllEmail <- function(dirName, isSpam = F) {
   
   # read all files in the directory
   messages <- readEmail(dirName)
   
   fileNames <- names(messages)
   n <- length(messages)
   
   # split header from body
   eSplit <- lapply(messages, splitMessage)
   rm(messages)
   
   # process header as named character vector
   headerList <- lapply(eSplit, function(msg)
                           processHeader(msg$header))
                        
   # extractd content-type key                        
   contentTypes <- sapply(headerList, function(header)
                                       header["Content-Type"])
   
   # extract the body
   bodyList <- lapply(eSplit, function(msg) msg$body)
   rm(eSplit)
   
   # which email have attachements
   hasAttach <- grep("^ *multi", tolower(contentTypes))
   
   # get summary stats for attachments and the shorter body
   attList <- mapply(processAttach, bodyList[hasAttach],
                     contentTypes[hasAttach], SIMPLIFY = F)
   
   bodyList[hasAttach] <- lapply(attList, function(attEl)
                                             attEl$body)
   
   attachInfo <- vector("list", length = n)
   attachInfo[ hasAttach ] <- lapply(attList,
                                     function(attEl) attEl$attachDf)
   
   # prepare return structure
   emailList <- mapply(function(header, body, attach, isSpam) {
      list(isSpam = isSpam, header = header,
           body = body, attach = attach)
   },
   headerList, bodyList, attachInfo,
   rep(isSpam, n), SIMPLIFY = F)

   names(emailList) <- fileNames
   
   invisible(emailList)
}

```

```{r}
emailStruct <- mapply(processAllEmail, directories,
                      isSpam = rep( c(F, T), 3:2))
emailStruct <- unlist(emailStruct, recursive = F)
```

```{r}
sampleStruct <- emailStruct[ 1:15 ]
```

### Deriving Variables from the email Messages

```{r}
header <- sampleStruct[[1]]$header
subject <- header["Subject"]
els <- strsplit(subject, "")
all(els %in% LETTERS)

testSubject <- c("DEAR MADAM", "WINNER!", "")

els <- strsplit(testSubject, "")
sapply(els, function(subject) all(subject %in% LETTERS))

gsub("[[:punct:] ]", "", testSubject)
gsub("[^[:alpha:]]", "", testSubject)

```

```{r}
isYelling <- function(msg) {
   if( "Subject" %in% names(msg$header) ) {
      el <- gsub("[^[:alpha:]]", "", msg$header["Subject"])
      
      if ( nchar(el) > 0 )
         nchar(gsub("[A-Z]", "", el) < 1 )
      else
         FALSE
   } else {
      NA
   }
}

perCaps <- function(msg) {
   
   body <- paste(msg$body, collapse = "")
   
   # Return NA if the body of the message is "empty"
   if(length(body) == 0 || nchar(body) == 0) return (NA)
   
   # Eliminate non-alpha characters
   body <- gsub("[^[:alpha:]]", "", body)
   capText <- gsub("[^A-Z]", "", body)
   100 * nchar(capText)/nchar(body)
}

```

```{r}
sapply(sampleStruct, perCaps)
```

```{r}

funcList <- list(
   
   isRe = function(msg) {
      "Subject" %in% names(msg$header) &&
         length(grep("^[ ]*Re:", msg$header[["Subject"]])) > 0
   },
   numLines = function(msg) {
      length(msg$body)
   },
   isYelling = function(msg) {
      if( "Subject" %in% names(msg$header) ) {
         el <- gsub("[^[:alpha:]]", "", msg$header["Subject"])
         
         if ( nchar(el) > 0 )
            nchar(gsub("[A-Z]", "", el) < 1 )
         else
            FALSE
      } else {
         NA
      }
   },
   perCaps = function(msg) {
      
      body <- paste(msg$body, collapse = "")
      
      # Return NA if the body of the message is "empty"
      if(length(body) == 0 || nchar(body) == 0) return (NA)
      
      # Eliminate non-alpha characters
      body <- gsub("[^[:alpha:]]", "", body)
      capText <- gsub("[^A-Z]", "", body)
      100 * nchar(capText)/nchar(body)
   }
)

```

```{r}
lapply(funcList, function(func)
   sapply(sampleStruct, function(msg) func(msg)))
```

```{r}
createDerivedF <- function(email = emailStruct, operations = funcList,
                           verbose = F)
{
   els <- lapply(names(operations),
                 function(id) {
                     if(verbose) print(id)
                     e <- operations[[id]]
                     v <- if(is.function(e))
                           sapply(email, e)
                        else
                           sapply(email, function(msg) eval(e))
                     v
                  })
   
   df <- as.data.frame(els)
   names(df) <- names(operations)
   
   invisible(df)  
}
```

```{r}
sampleDF <- createDerivedF(sampleStruct)

```

```{r}
spam_data <- file.path(data.dir, "spamAssassinDerivedDF.rda")

load(spam_data)
```

```{r}
perCaps2 <- function(msg) {
   
   body <- paste(msg$body, collapse = "")
 
   # return NA if the body of the message is "empty"
   if(length(body) == 0 || nchar(body) == 0) return(NA)
   
   # eliminate non-alpha characters and empty lines
   body <- gsub("[^[:alpha:]]", "", body)
   els <- unlist(strsplit(body, ""))
   ctCap <- sum(els %in% LETTERS)
   100 * ctCap / length(els)
}

```

```{r}
pC <- sapply(emailStruct, perCaps)
pC2 <- sapply(emailStruct, perCaps2)

identical(pC, pC2)
```

```{r}
indNA <- which(is.na(emailDF$subExcCt))

indNoSubject <- which(sapply(emailStruct,
                             function(msg)
                                !("Subject" %in% names(msg$header))))

all(indNA == indNoSubject)
```

```{r}
all(emailDF$bodyCharCt > emailDF$numLines)
```

```{r}

long_lines <- head(sort(emailDF$numLines, decreasing = T), 10)

rem <- which(emailDF$numLines %in% long_lines)

ggplot(emailDF[-rem, ], aes(bodyCharCt, numLines)) +
   geom_point(aes(col = bodyCharCt)) +
   geom_smooth(method = "lm") +
   scale_x_continuous(lim = c(0, 35000))

```

#### Exploring the email Feature Set

```{r}
percent <- emailDF$perCaps
isSpamLabs <- factor(emailDF$isSpam, labels = c("ham", "spam"))
boxplot(log(1 + percent) ~ isSpamLabs,
        ylab = "Percent Capitals (log)")

```

```{r}

ggplot(emailDF, aes(perCaps, bodyCharCt, col = isSpam)) +
   geom_point() +
   scale_y_log10() +
   scale_x_log10()

```

```{r}

colI <- c("#4DAF4A80", "#984EA380")
logBodyCharCt <- log(1 + emailDF$bodyCharCt)
logPerCaps <- log(1 + emailDF$perCaps)
plot(logPerCaps ~ logBodyCharCt, xlab = "Total Characters (log)",
     ylab = "Percent Capitals (log)",
     col = colI[1 + emailDF$isSpam],
     xlim = c(2, 12), pch = 19, cex = 0.5)
```

```{r}
table(emailDF$numAtt, isSpamLabs)
```

```{r}
colM <- c("#E41A1C80", "#377EB880")
isRe <- factor(emailDF$isRe, labels = c("no Re:", "Re:"))
mosaicplot(table(isSpamLabs, isRe), main = "",
           xlab = "", ylab = "", color = colM)

fromNE <- factor(emailDF$numEnd, labels = c("No #", "#"))
mosaicplot(table(isSpamLabs, fromNE), color = colM,
           main = "", xlab = "", ylab = "")
```

### Fitting Recursive Partition

```{r}
setupRpart <- function(data) {
   logicalVars <- which(sapply(data, is.logical))
   facVars <- lapply(data[, logicalVars],
                     function(x) {
                        x = as.factor(x)
                        levels(x) = c("F", "T")
                        x
                     })
   cbind(facVars, data[, - logicalVars])
}

emailDFrp <- setupRpart(emailDF)
```

```{r}
set.seed(418910)

numSpam <- sum(isSpam)
numHam <- numEmail - numSpam

testSpamIdx <- sample(numSpam, size = floor(numSpam/3))
testHamIdx <- sample(numHam, size = floor(numHam/3))

testDF <- rbind( emailDFrp[ emailDFrp$isSpam == "T", ][testSpamIdx, ],
                 emailDFrp[ emailDFrp$isSpam == "F", ][testHamIdx, ])

trainDF <- rbind( emailDFrp[ emailDFrp$isSpam == "T", ][-testSpamIdx, ],
                 emailDFrp[ emailDFrp$isSpam == "F", ][-testHamIdx, ])

```

```{r}
rpartFit <- rpart(isSpam ~ ., data = trainDF, method = "class")

prp(rpartFit, extra = 1)
```

```{r}
predictions <- predict(rpartFit,
                       newdata = testDF[, names(testDF) != "isSpam"],
                       type = "class")

predsForHam <- predictions[ testDF$isSpam == "F" ]
summary(predsForHam)

sum(predsForHam == "T", na.rm = T) / length(predsForHam)

predsForSpam <- predictions[ testDF$isSpam == "T" ]
sum(predsForSpam == "F", na.rm = T) / length(predsForSpam)
```

```{r}
args(rpart.control)
```

```{r}
complexityVals <- c(seq(0.00001, 0.0001, length = 19),
                    seq(0.0001, 0.001, length = 19),
                    seq(0.001, 0.005, length = 9),
                    seq(0.005, 0.01, length = 9))

fits <- lapply(complexityVals, function(x) {
   rpartObj <- rpart(isSpam ~ ., data = trainDF,
                     method = "class",
                     control = rpart.control(cp=x))
   
   predict(rpartObj,
           newdata = testDF[, names(testDF) != "isSpam"],
           type = "class")
})

```
 
```{r}
spam <- testDF$isSpam == "T"
numSpam <- sum(spam, na.rm = T)
numHam <- sum(!spam, na.rm = T)

errs <- sapply(fits, function(preds) {
   typeI = sum( preds[ !spam ] == "T", na.rm = T) / numHam
   typeII = sum( preds[ spam ] == "F", na.rm = T) / numSpam
   c(typeI = typeI, typeII = typeII )
})

errs

err_df <- data.table(t(errs))

```
 
### Further Analysis

### 1.)

We hand-selected email to belong to the sample set in the _sampleEmail_. Instead of this approach, use the sample function to choose messages at random for the sample. Be sure to take files from all 5 directories of the email.

```{r}
dir <- directories[1]

dir_lens <- sapply(directories, function(dir) length(list.files(dir)))

new_sample <- sapply(directories[ dir_lens > 1 ], function(dir) {
  file_list <- list.files(dir)
  
  n <- length(file_list)

  idx <- sample(1:n, 30)
  
  return(file_list[idx])
})

new_sample

```

### 2.) In the text mining approach to detecting spam we ignored all attachments in creating the set of words belonging to a message (see Section 3.5.2). Write a function to extract words from any plain text or HTML attachment and include these words in the set of a message's words. Try to reuse _findMsg()_ function and modify the _dropAttach()_ function to accept an additional parameter that indicates whether or not the words in the attachments are to be extracted.

```{r}

index <- hasAttach[2]

boundary <- getBoundary(headerList[[index]])
body <- sampleSplit[[index]]$body
body

includeAttach <- function(body, boundary) {
   
   if(is.null(body)) {
      return("")
   }
   
   bString <- paste("--", boundary, sep = "")
   bStringLocs <- which(bString == body)
   
   eString <- paste("--", boundary, "--", sep = "")
   eStringLoc <- which(eString == body)
   
   return(msg)
}

```

### 3.)

The string manipulation functions in R can be used instead of regular expression functions for finding, changing and extracting substrings from strings. These functions include: _strsplit()_ to divide a string up into pieces, _substr()_ to extract a portion of a string, _paste()_ to glue together multiple strings, and _nchar()_, which returns the number of characters in a string. Write your own version of the get boundary strings from the Content-Type.

```{r}

header <- sampleSplit[[6]]$header
boundaryIdx <- grep("boundary=", header)
header[boundaryIdx]

boundary <- header[ str_which(header, "boundary=") ]
pieces <- unlist(strsplit(boundary, '='))
pieces <- pieces[ str_which(pieces, ";") ]


sub(".*boundary=\"(.*)\";.*", "\\1", header[boundaryIdx])

header2 <- headerList[[9]]
boundaryIdx2 <- grep("boundary=", header2)
header2[boundaryIdx2]

sub('.*boundary="(.*)";.*', "\\1", header2[boundaryIdx2])

boundary2 <- gsub('"', "", header2[boundaryIdx2])

sub(".*boundary= *(.*);?.*", "\\1", boundary2)

boundary <- gsub('"', "", header[boundaryIdx])
sub(".*boundary= *(.*);?.*", "\\1", boundary)

getBoundary2 <- function(header) {
   boundary <- header[ str_which(header, "boundary=") ]
   pieces <- unlist(strsplit(boundary, '='))
   pieces <- pieces[ str_which(pieces, ";") ]
   paste("==", pieces, sep = "")
}

getBoundary(header)
getBoundary2(header)
```

### 4.)

Write the __dropAttach()_ function for Section 3.5.2. This funciton has two inputs, the body of a mkessage and the boundary string that marks the location of the attachments. It returns the body without its attachments. Include in the return value the lines of the body that follow the first boundary string up to the string marking the first attachment and the lines following the ending boundary string. Be sure to consider the idiosyncratic cases of no attachments and a missing ending boundary string.

```{r}
processAttach <- function(body, contentType ) {

   boundary <- getBoundary(contentType)

   bString <- paste("--", boundary, sep = "")
   bStringLocs <- which(bString == body)

   eString <- paste("--", boundary, "--", sep = "")
   eStringLoc <- which(eString == body)
   
   n <- length(body)
   
   if(length(bStringLocs) == 2) {
      
      bodyContent <- body[(bStringLocs[1] + 2):(bStringLocs[2] - 1)]

      emptyLines <- which(bodyContent == "")
      bodyContent <- bodyContent[ - emptyLines]
    
      attachContent <- body[(bStringLocs[2] + 1):n]
      
      aLen <- diff(c(bStringLocs[-1], eStringLoc))
      aType <- body[bStringLocs[-1] + 1]
      
      if(length(aLen) == length(aType)) {      
         attachments <- data.frame(aLen = aLen, aType = aType)
      } else {
         attachments <- data.frame(aLen = c(), aType = c())
      }
      
   } else {
      if( length(bStringLocs) == 0 ) {
         bodyContent <- body
      } else {
         bodyContent = body
      }
      attachments <- data.frame(aLen = c(), aType = c())
   }
   
   return(list(body = bodyContent, attachDF = attachments ))
}

```

### 5.)

Write the function __findMsgWords()__ of Section 3.5.3. This function takes as input the message body (with no attachments) and the return value is a vector of the unique words in the message. That is, we only track which words are in the message, not the number of times these words appear in the message. Consider wheather it is simpler to split the string by blanks first and then process the puncuation, digits, etc. The function should convert capital letters to lower case and drop all stop words and words that are only one letter long. A vector of stop words is avaliable in the tm package.

```{r}
msg <- sampleSplit[[3]]$body
msg

findMsgWords <- function(msg) {

}

words <- unlist(sapply(msg, function(line) strsplit(line, " ")))
names(words) <- ""

n <- length(words)

msg_words <- vector(mode = "character")

for(i in 1:n)
{
   word <- tolower(words[i])
   
   if( word %in% exclude_word_list) {
      next
   }
   
   
}

tw <- "http://us.click.yahoo.com/pt6YBB/NXiEAA/mG3HAA/7gSolB/TM"

gsub(tw, pattern = "(//)", "")

exclude_word_list
```

### 6.)